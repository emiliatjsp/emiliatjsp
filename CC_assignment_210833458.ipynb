{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emiliatjsp/emiliatjsp/blob/main/CC_assignment_210833458.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1><b>ECS7022P: Computational Creativity Assignment</b></h1>\n",
        "<h2>Emilia Pietras, ID: 210833458<br/></center>"
      ],
      "metadata": {
        "id": "_KEHXhyBXWMX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HNMp-67JTh2"
      },
      "source": [
        "## 1. Logistics Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNd02O_MH2Pj"
      },
      "outputs": [],
      "source": [
        "#!pip install bs_ds\n",
        "#!pip install fake_useragent\n",
        "#!pip install lxml\n",
        "#!pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7mQoI-OH6RO"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "\n",
        "\n",
        "def get_movies(genre):\n",
        "    \"\"\"\n",
        "    Gets a genre and returns a list of the movie titles on imsdb.com in that \n",
        "    genre.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    genre : str\n",
        "        A string describing the genre of movies we will scrape\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    movies : list\n",
        "        A list of strings with movie titles \n",
        "    \"\"\"    \n",
        "\n",
        "    # the complete list of genres we can choose\n",
        "    genres = ['Action','Adventure','Animation','Comedy','Crime','Drama',\n",
        "              'Family','Fantasy','Film-Noir','Horror','Musical','Mystery',\n",
        "              'Romance','Sci-Fi','Short','Thriller','War','Western']\n",
        "\n",
        "    if genre not in genres:\n",
        "        raise ValueError(\"the input 'genre' must be one of the following: \"+str(genres))\n",
        "    \n",
        "    url = 'https://imsdb.com/genre/'+genre \n",
        "    \n",
        "    # Connecting to the url using requests.get and add timeout (mult. of 3), the status code is 200 if success\n",
        "    response = requests.get(url, timeout=3)\n",
        "\n",
        "    page_content = response.content\n",
        "    soup = BeautifulSoup(page_content,'lxml') \n",
        "\n",
        "    # The third table (column) on the webpage contains the links to all the movies\n",
        "    find_tables = soup.findAll('td', valign='top') # the three tables have the tag <td>\n",
        "    all_movies = find_tables[2].findAll('a') # <a> --> links!\n",
        "\n",
        "    # Build the final list of tuples, which is to be returned\n",
        "    movies = [re.split(\"[,.]\",movie_info.string)[0].replace(' ', '-')\n",
        "              for movie_info in all_movies]\n",
        "    return movies\n",
        "\n",
        "def handle_movie(movie):\n",
        "    \"\"\"\n",
        "    Gets a movie title and returns a list containing lines of the script\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    movie : str\n",
        "        A movie title\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    text : list\n",
        "        A list of strings, which are the lines of the script\n",
        "    \"\"\"    \n",
        "\n",
        "    text = []\n",
        "    url = u'http://www.imsdb.com/scripts/' + movie + '.html' # full url to the movie script\n",
        "    response = requests.get(url, timeout=3)\n",
        "    if response.status_code==200:\n",
        "        page_content = response.content\n",
        "        soup = BeautifulSoup(page_content,'lxml')\n",
        "        for b_tag in soup.find_all('b'): # checking for the <b> tag\n",
        "            text.append(b_tag.text)\n",
        "            if (b_tag.next_sibling != \"\") and b_tag.next_sibling not in soup.find_all('b'):                \n",
        "            #text.append(b_tag.text)\n",
        "                text.append(b_tag.next_sibling)\n",
        "    else: \n",
        "        print('Error. Check status code table.\\n\\n')\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kNFR1gZIhFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b496ac-1d66-433d-89ca-a4d23d68814d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncomedy_movies = get_movies(\\'Comedy\\')\\nall_text = []\\nfor movie in comedy_movies[:70]: # keeping the text file under 10MB\\n    all_text.append(handle_movie(movie))\\n\\nall_lines = \"\"\\nfor doc in all_text:\\n    for line in doc:\\n        all_lines = all_lines + str(line)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "### SCRAPING COMEDY MOVIES\n",
        "\"\"\"\n",
        "comedy_movies = get_movies('Comedy')\n",
        "all_text = []\n",
        "for movie in comedy_movies[:70]: # keeping the text file under 10MB\n",
        "    all_text.append(handle_movie(movie))\n",
        "\n",
        "all_lines = \"\"\n",
        "for doc in all_text:\n",
        "    for line in doc:\n",
        "        all_lines = all_lines + str(line)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYKFHix5IpRL"
      },
      "outputs": [],
      "source": [
        "# WRITING COMEDY MOVIES TRAINING DATA\n",
        "#f = open(\"comedy_movies.txt\", \"w\") # creating a .txt file\n",
        "#f.write(all_lines)\n",
        "#f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "horror_movies = get_movies('Horror')\n",
        "all_text = []\n",
        "for movie in horror_movies[:70]: # keeping the text file under 10MB\n",
        "    all_text.append(handle_movie(movie))\n",
        "\n",
        "all_lines = \"\"\n",
        "for doc in all_text:\n",
        "    for line in doc:\n",
        "        all_lines = all_lines + str(line)\n",
        "\"\"\"        "
      ],
      "metadata": {
        "id": "LwD9ZOa63taI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a63695b-8b75-4f2e-e356-b90c0e27c298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhorror_movies = get_movies(\\'Horror\\')\\nall_text = []\\nfor movie in horror_movies[:70]: # keeping the text file under 10MB\\n    all_text.append(handle_movie(movie))\\n\\nall_lines = \"\"\\nfor doc in all_text:\\n    for line in doc:\\n        all_lines = all_lines + str(line)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#f = open(\"horror_movies.txt\", \"w\") # creating a .txt file\n",
        "#f.write(all_lines)\n",
        "#f.close()"
      ],
      "metadata": {
        "id": "dTNyV0VrMtFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv2OuHF1JOH4"
      },
      "source": [
        "## 2. Training Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loZBoEiIJMe2"
      },
      "outputs": [],
      "source": [
        "#!pip install -q gpt-2-simple\n",
        "#import gpt_2_simple as gpt2\n",
        "#from datetime import datetime\n",
        "#from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l9A4T7LJZXR"
      },
      "outputs": [],
      "source": [
        "#gpt2.download_gpt2(model_name=\"124M\") # downloading the 124M GPT-2 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67S7YIcRJbBZ"
      },
      "outputs": [],
      "source": [
        "#gpt2.mount_gdrive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMVDH_3hJf9O",
        "outputId": "afa6386d-244e-4d66-e15d-eaa35794857c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport tensorflow as tf\\nimport json\\n\\ntf.compat.v1.reset_default_graph() \\n\\nsess = gpt2.start_tf_sess()\\n\\n# finetuning\\ngpt2.finetune(sess,\\n              dataset=\"horror_movies.txt\",\\n              model_name=\\'124M\\',\\n              steps=2000,\\n              restore_from= \\'latest\\', #\\'fresh\\n              overwrite = True, #!!!\\n              run_name=\\'horror\\',\\n              print_every=10,\\n              sample_every=200,\\n              save_every=400,\\n\\t          only_train_transformer_layers = True,\\n\\t          accumulate_gradients = 1,\\n              )\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "import json\n",
        "\n",
        "tf.compat.v1.reset_default_graph() \n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "# finetuning\n",
        "gpt2.finetune(sess,\n",
        "              dataset=\"horror_movies.txt\",\n",
        "              model_name='124M',\n",
        "              steps=2000,\n",
        "              restore_from= 'latest', #'fresh\n",
        "              overwrite = True, #!!!\n",
        "              run_name='horror',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=400,\n",
        "\t          only_train_transformer_layers = True,\n",
        "\t          accumulate_gradients = 1,\n",
        "              )\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gpt2.copy_checkpoint_to_gdrive(run_name='horror', copy_folder=True)"
      ],
      "metadata": {
        "id": "92PciDqCBp0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Generation Code"
      ],
      "metadata": {
        "id": "vWDmARYAXNZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gpt-2-simple\n",
        "!pip install --upgrade --no-cache-dir gdown\n"
      ],
      "metadata": {
        "id": "dYJqy3c0Zx1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c704c261-c8ba-42ef-8290-522f7deb9062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt_2_simple as gpt2\n",
        "gpt2.mount_gdrive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1BOteA4b-qx",
        "outputId": "5a3a4212-22d0-4144-c4a8-d49680e68652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown, os\n",
        "\n",
        "url = \"https://drive.google.com/drive/folders/1tqdVl1dOVdeqGaSIJWuuyRukg3OOH81c\"\n",
        "\n",
        "download_successful = None # A workaround to make sure that gdown downloads the whole folder successfully, see https://github.com/wkentaro/gdown/issues/43\n",
        "while download_successful == None:\n",
        "  download_successful = gdown.download_folder(url, quiet=True, use_cookies=False)\n",
        "  os.system('rm ~/.cache/gdown/cookies.json')"
      ],
      "metadata": {
        "id": "8JbmFPHCRFMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading in one model to allow for \"reuse\" in the text generation section\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ebh6BIWkjYq",
        "outputId": "0e836835-47ce-4965-eda0-fc720288bd50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/run1/model-4000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Text Generation\n",
        "\n",
        "genre = \"horror\" #@param['comedy', 'horror']\n",
        "if genre == \"comedy\":\n",
        "    genre = \"run1\"\n",
        "    sess = gpt2.start_tf_sess()\n",
        "    gpt2.load_gpt2(sess, run_name='run1', reuse=True)\n",
        "else:\n",
        "    sess = gpt2.start_tf_sess()\n",
        "    gpt2.load_gpt2(sess, run_name='horror', reuse=True)\n",
        "\n",
        "prefix = \"CUT TO: \"  # @param {type: \"string\"}\n",
        "\n",
        "output_length = 512 # @param {type: \"integer\"}\n",
        "nsamples =  2# @param {type: \"integer\"}\n",
        "temperature = 1.0 # @param\n",
        "top_p = 0.9 # @param\n",
        "batch_size = nsamples\n",
        "\n",
        "gpt2.generate(sess, run_name=genre, prefix=prefix, length=output_length, batch_size = batch_size, nsamples=nsamples, temperature = temperature)"
      ],
      "metadata": {
        "id": "NkJ40adCZTdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c5d3b6-9a48-4698-d698-2549815af337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/horror/model-4000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/horror/model-4000\n",
            "CUT TO:                                                       79\n",
            "\n",
            "                                  CARRIE\n",
            "                 Emily's right. I was closing that file...\n",
            "\n",
            "                                 CARRIE\n",
            "                 Excuse me, you were looking at names!\n",
            "                 Please... please... give me an e-\n",
            "                 X-Ray... assume you're dead.\n",
            "\n",
            "                                CARRIE\n",
            "                 That's irresponsible! Now go ahead...\n",
            "\n",
            "     Ana, Carrae and Marko are there watching as Carrae rounds Leila's\n",
            "\n",
            "      B.G. Penalty for different actions on amigos...\n",
            "                                                              85.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                           CUT TO:                    81.\n",
            "\n",
            "\n",
            "41  INT. CARRIE'S PELLEA TRAILER - NIGHT      \n",
            "====================\n",
            "CUT TO:         82 WATCH\n",
            "           102 OMITTED \n",
            "                          \n",
            "                                                ROSE\n",
            "                          -Rose's right hand is cut off.\n",
            "                          \n",
            "                                               ROSE\n",
            "                           Anything else?\n",
            "                          (to Rose)\n",
            "                   The the life --\n",
            "\n",
            "                                                  ROSE\n",
            "                    What's the life extension?\n",
            "\n",
            "                                              ROSE\n",
            "                    To the point where the skin is served\n",
            "                    right through the sanctuary of feelings,\n",
            "                    watching you dimly take a piss.\n",
            "     \n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20/04/2020 Edit:\n",
        "\n",
        "Link to GitHub"
      ],
      "metadata": {
        "id": "aRNtXpRXqxTe"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_HNMp-67JTh2",
        "Tv2OuHF1JOH4"
      ],
      "name": "CC_assignment_210833458.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}